{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6326ea6c",
   "metadata": {},
   "source": [
    "# On Sale - ECD I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac05e07",
   "metadata": {},
   "source": [
    "### Takeways - 02/10/2022\n",
    "\n",
    "Firstly I need to know if the score on the leaderboard is equivalent to the accuracy here. If so, the professor wants us to overfit the data. If not, how can I know if I am being good enough to post my results on kaggle?\n",
    "*R: my accuracy here is the actual score on the leaderboard!*\n",
    "\n",
    "Ideas of models/changes that I can implement and submit:\n",
    "1. Decision Tree Classifier\n",
    "2. Decision Tree Classifier w/ different missing values imputation\n",
    "3. Logistic Regression for Classification Task\n",
    "4. Random Forest for Classification Task\n",
    "5. XGBoost for Classification Task (learn more)\n",
    "6. Ensemble Model Stacking (learn more)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e233190",
   "metadata": {},
   "source": [
    "### Takeways - 04/10/2022\n",
    "\n",
    "NaN values - I should check the min/max and quartiles of the continuous variables. If I have outliers, I could use the median as input instead of the mean\n",
    "\n",
    "Continuous variables - I could use encoders to transform them into discrete variables and see the results\n",
    "\n",
    "Algorithm - attention to the hyperparameters!\n",
    "\n",
    "Variable Selection -  keep only the variables that are significant to our analysis\n",
    "\n",
    "IMPORTANT - the variable w/ missing values is a continuous variables! -> variable x9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e2bcda",
   "metadata": {},
   "source": [
    "## First Step - Deal with NaN Values and Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c184e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change directory\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir(\"//Users//enzoaaragao//Downloads//on-sale-ecd1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "e6e2af4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"training.csv\")\n",
    "test = pd.read_csv(\"task.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0bb6a680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2920\n",
       "1     756\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba94b0b",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35c74f8",
   "metadata": {},
   "source": [
    "### 1.1. Dealing w/ NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "909fbc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i      False\n",
       "y      False\n",
       "d1     False\n",
       "d2     False\n",
       "d3     False\n",
       "d4     False\n",
       "d5     False\n",
       "d7     False\n",
       "d8     False\n",
       "d9     False\n",
       "d10    False\n",
       "d11    False\n",
       "d12    False\n",
       "d13    False\n",
       "d14    False\n",
       "d15    False\n",
       "d16    False\n",
       "d17    False\n",
       "d18    False\n",
       "x1     False\n",
       "x2     False\n",
       "x3     False\n",
       "x4     False\n",
       "x5     False\n",
       "x6     False\n",
       "x7     False\n",
       "x8     False\n",
       "x9      True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3831093b",
   "metadata": {},
   "source": [
    "##### The column \"x9\" has NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "945f5b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3627.000000\n",
       "mean       26.316515\n",
       "std        15.518175\n",
       "min         1.000000\n",
       "25%        13.500000\n",
       "50%        28.000000\n",
       "75%        40.000000\n",
       "max        54.000000\n",
       "Name: x9, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if the \"x9\" column has a minimal value of zero - in this way could be a ab opportunity to replace the NaN values w/ zero\n",
    "train[\"x9\"].describe()\n",
    "\n",
    "#Nevertheless, we see that the minimal value of one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bf21f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean value is 26.316515026192445\n",
      " \n",
      "the median value is 28.0\n",
      " \n",
      "the mode value is 0    2.0\n",
      "Name: x9, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"the mean value is\", train[\"x9\"].mean())\n",
    "print(\" \")\n",
    "print(\"the median value is\", train[\"x9\"].median())\n",
    "print(\" \")\n",
    "print(\"the mode value is\", train[\"x9\"].mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e5021",
   "metadata": {},
   "source": [
    "As we can see, the mode significantly diverges from the mean and median. On the other hand, the mean and median are close from each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00371c6f",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/whats-the-best-way-to-handle-nan-values-62d50f738fc --- the problem with using the mean, mode, or median values of the column as input for the NaN values only takes into account the value of the respective column. Nevertheless, I can use methods such as KNN and MICE that takes into account the whole dataset to input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "c5a36922",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train.iloc[:,2:len(train.columns)]\n",
    "y_train=train.iloc[:,1]\n",
    "X_test=test.iloc[:,2:len(test.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "710a1226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterative Imputer - MICE (I can also do w/ KNN)\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=1000, random_state=0)\n",
    "X_train=imp.fit_transform(X_train)\n",
    "X_test=imp.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "0b46b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standar Scaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46344c",
   "metadata": {},
   "source": [
    "I will think about the encoders later on -> now I am skipping to the Algo part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0faefe",
   "metadata": {},
   "source": [
    "### 1.2. Quartile Encorders of Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "8e8887bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "#X_train.describe()\n",
    "\n",
    "#17 = 1 to 2; 2 to 4; 4 to 6; 6 to 7\n",
    "#18 = 1 to 1; 1 to 2; 2 to 3; 3 to 4\n",
    "#19 = 0.001 to 0.350; 0.350 to 0.500; 0.500 to 0.750; 0.750 to 5\n",
    "#20 = 1 to 1; 1 to 1; 1 to 1; 1 to 3\n",
    "#21 = 0.39 to 1.09; 1.09 to 1.69: 1.69 to 2.82; 2.82 to 27.48\n",
    "#22 = 1 to 1; 1 to 5; 5 to 8; 8 to 17\n",
    "#23 = 1 to 4; 4 to 6; 6 to 12; 12 to 25\n",
    "#24 = 1 to 3; 3 to 4; 4 to 5; 5 to 12\n",
    "#25 = 1 to 14: 14 to 27.90; 27.90 to 40; 40 to 54\n",
    "\n",
    "X_train[17] = pd.cut(X_train[17], bins=4, labels = [1,2,3,4])\n",
    "X_train[18] = pd.cut(X_train[18], bins=3, labels = [1,2,3])\n",
    "X_train[19] = pd.cut(X_train[19], bins=4, labels = [1,2,3,4])\n",
    "X_train[20] = pd.cut(X_train[20], bins=2, labels = [1,2])\n",
    "X_train[21] = pd.cut(X_train[21], bins=4, labels = [1,2,3,4])\n",
    "X_train[22] = pd.cut(X_train[22], bins=3, labels = [1,2,3])\n",
    "X_train[23] = pd.cut(X_train[23], bins=4, labels = [1,2,3,4])\n",
    "X_train[24] = pd.cut(X_train[24], bins=4, labels = [1,2,3,4])\n",
    "X_train[25] = pd.cut(X_train[25], bins=4, labels = [1,2,3,4])\n",
    "\n",
    "X_test[17] = pd.cut(X_test[17], bins=4, labels = [1,2,3,4])\n",
    "X_test[18] = pd.cut(X_test[18], bins=3, labels = [1,2,3])\n",
    "X_test[19] = pd.cut(X_test[19], bins=4, labels = [1,2,3,4])\n",
    "X_test[20] = pd.cut(X_test[20], bins=2, labels = [1,2])\n",
    "X_test[21] = pd.cut(X_test[21], bins=4, labels = [1,2,3,4])\n",
    "X_test[22] = pd.cut(X_test[22], bins=3, labels = [1,2,3])\n",
    "X_test[23] = pd.cut(X_test[23], bins=4, labels = [1,2,3,4])\n",
    "X_test[24] = pd.cut(X_test[24], bins=4, labels = [1,2,3,4])\n",
    "X_test[25] = pd.cut(X_test[25], bins=4, labels = [1,2,3,4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cfabaa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3676 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...   16  17  18  19  \\\n",
       "0     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   2   1   1   \n",
       "1     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   1   2   1   \n",
       "2     1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   2   2   1   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0   2   1   1   \n",
       "4     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   2   2   1   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ..  ..  ..   \n",
       "3671  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   1   1   1   \n",
       "3672  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0   1   1   1   \n",
       "3673  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   3   1   1   \n",
       "3674  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  1.0   2   1   1   \n",
       "3675  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   2   2   1   \n",
       "\n",
       "      20  21  22 23 24 25  \n",
       "0      1   1   3  1  2  3  \n",
       "1      1   1   1  1  2  3  \n",
       "2      1   1   1  1  2  3  \n",
       "3      1   3   1  2  1  3  \n",
       "4      1   1   1  1  2  3  \n",
       "...   ..  ..  .. .. .. ..  \n",
       "3671   1   1   1  4  2  3  \n",
       "3672   1   1   1  2  2  2  \n",
       "3673   1   1   1  1  2  1  \n",
       "3674   1   1   3  1  1  2  \n",
       "3675   1   1   2  1  1  1  \n",
       "\n",
       "[3676 rows x 26 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f2ac5",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754fe0f6",
   "metadata": {},
   "source": [
    "## Second Step - Algorithm and Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e74670d",
   "metadata": {},
   "source": [
    "### 2.1. Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "84661584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "reg = LogisticRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred_lr = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "af0f1717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87      2920\n",
      "           1       0.26      0.07      0.11       756\n",
      "\n",
      "    accuracy                           0.77      3676\n",
      "   macro avg       0.53      0.51      0.49      3676\n",
      "weighted avg       0.69      0.77      0.71      3676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_train,y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9d9ba9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred_dtc = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dfb50c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      2920\n",
      "           1       0.21      0.21      0.21       756\n",
      "\n",
      "    accuracy                           0.67      3676\n",
      "   macro avg       0.50      0.50      0.50      3676\n",
      "weighted avg       0.68      0.67      0.68      3676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_train,y_pred_dtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3a56acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred_rf = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e60d7ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      2920\n",
      "           1       0.21      0.19      0.20       756\n",
      "\n",
      "    accuracy                           0.68      3676\n",
      "   macro avg       0.50      0.50      0.50      3676\n",
      "weighted avg       0.68      0.68      0.68      3676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_train,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "69fb3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine (SVM)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svm = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4a70533f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86      2920\n",
      "           1       0.23      0.07      0.10       756\n",
      "\n",
      "    accuracy                           0.76      3676\n",
      "   macro avg       0.51      0.50      0.48      3676\n",
      "weighted avg       0.68      0.76      0.71      3676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_train,y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8ea70f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Nearest Neighbour (KNN)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "661f3879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      2920\n",
      "           1       0.23      0.19      0.21       756\n",
      "\n",
      "    accuracy                           0.71      3676\n",
      "   macro avg       0.52      0.51      0.51      3676\n",
      "weighted avg       0.68      0.71      0.69      3676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_train,y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "31ef6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_nb = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1eed6260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.53      0.64      2920\n",
      "           1       0.20      0.44      0.27       756\n",
      "\n",
      "    accuracy                           0.52      3676\n",
      "   macro avg       0.49      0.49      0.45      3676\n",
      "weighted avg       0.67      0.52      0.56      3676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_train,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "27a571c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTE\n",
    "#Model Pipeline\n",
    "\n",
    "model_pipeline = []\n",
    "model_pipeline.append(LogisticRegression(solver='liblinear'))\n",
    "model_pipeline.append(SVC())\n",
    "model_pipeline.append(KNeighborsClassifier())\n",
    "model_pipeline.append(DecisionTreeClassifier())\n",
    "model_pipeline.append(RandomForestClassifier())\n",
    "model_pipeline.append(GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8c3d4776",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTE\n",
    "#Model Evaluation\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model_list = ['Logistic Regression', 'SVM', 'KNN', 'Decision Tree', 'Random Forest', 'Naive Bayes']\n",
    "acc_list = []\n",
    "auc_list = []\n",
    "cm_list = []\n",
    "\n",
    "for model in model_pipeline:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc_list.append(metrics.accuracy_score(y_train, y_pred))\n",
    "    fpr, tpr, _thresholds = metrics.roc_curve(y_train, y_pred)\n",
    "    auc_list.append(round(metrics.auc(fpr, tpr),2))\n",
    "    cm_list.append(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4261f167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.770131</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.760881</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.705658</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.673558</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.684712</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.515506</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy   AUC\n",
       "0  Logistic Regression  0.770131  0.51\n",
       "1                  SVM  0.760881  0.50\n",
       "2                  KNN  0.705658  0.51\n",
       "3        Decision Tree  0.673558  0.50\n",
       "4        Random Forest  0.684712  0.51\n",
       "5          Naive Bayes  0.515506  0.49"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TESTE\n",
    "#Accuracy and AUC\n",
    "\n",
    "result_df_cont = pd.DataFrame({'Model':model_list, 'Accuracy': acc_list, 'AUC': auc_list})\n",
    "result_df_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "da862d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.770131</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.760881</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.705658</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.673558</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.684712</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.515506</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy   AUC\n",
       "0  Logistic Regression  0.770131  0.51\n",
       "1                  SVM  0.760881  0.50\n",
       "2                  KNN  0.705658  0.51\n",
       "3        Decision Tree  0.673558  0.50\n",
       "4        Random Forest  0.684712  0.51\n",
       "5          Naive Bayes  0.515506  0.49"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_d = pd.DataFrame({'Model':model_list, 'Accuracy': acc_list, 'AUC': auc_list})\n",
    "result_df_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f42f05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decision Tree Classifier w/ Encoders - Teste 1\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_dtc})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//dtc_cat_1.csv\",index=False)\n",
    "\n",
    "# Nota baixa: 0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e5b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decision Tree Classifier w/ Encoders - Teste 1\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_dtc})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//dtc_cat_1.csv\",index=False)\n",
    "\n",
    "# Nota: 0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "38ba63a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest w/ Encoders - Teste 1\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_rf})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//rf_cat_1.csv\",index=False)\n",
    "\n",
    "# Nota: 0.84\n",
    "# Random Forest w/ MICE Nan Values and Quantile Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bee73ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Naive Bayes w/ Encoders - Teste 1\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_nb})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//nb_cat_1.csv\",index=False)\n",
    "\n",
    "# Nota: 0.36\n",
    "# Naive Bayes w/ MICE Nan Values and Quantile Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d6cb063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVM w/ Encoders - Teste 1\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_svm})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//svm_cat_1.csv\",index=False)\n",
    "\n",
    "# Nota: 0.80\n",
    "# SVM w/ MICE Nan Values and Quantile Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4800bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LR w/ Encoders - Teste 1\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_lr})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//lr_cat_1.csv\",index=False)\n",
    "\n",
    "# Nota: 0.81\n",
    "# LR w/ MICE Nan Values and Quantile Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a5d98a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decision Tree Classifier - Teste 2\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_dtc})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//dtc_1.csv\",index=False)\n",
    "\n",
    "# Nota: 0.947\n",
    "# DTC w/ MICE Nan Values Max_iter = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "faf627b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest - Teste 2\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_rf})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//rf_1.csv\",index=False)\n",
    "\n",
    "# Nota: 0.954\n",
    "# Random Forest w/ MICE Nan Values Max_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e42d9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVM - Teste 2\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_svm})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//svm_1.csv\",index=False)\n",
    "\n",
    "# Nota: 0.\n",
    "# SVM w/ MICE Nan Values Max_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d90376a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Naive Bayes - Teste 2\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_nb})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//nb_1.csv\",index=False)\n",
    "\n",
    "# Nota: 0.63\n",
    "# NB w/ MICE Nan Values Max_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2964e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest - Teste 3\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_rf})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//rf_2.csv\",index=False)\n",
    "\n",
    "# Nota: 0.950\n",
    "# RF Scaled w/ MICE Nan Values Max_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d5804055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_model = BaggingClassifier(\n",
    "    base_estimator = DecisionTreeClassifier(),\n",
    "    n_estimators = 100,\n",
    "    max_samples=0.8,\n",
    "    oob_score=True,\n",
    ")\n",
    "\n",
    "bag_model.fit(X_train, y_train)\n",
    "y_pred_bag = bag_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b39b160d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      2920\n",
      "           1       0.21      0.21      0.21       756\n",
      "\n",
      "    accuracy                           0.68      3676\n",
      "   macro avg       0.50      0.50      0.50      3676\n",
      "weighted avg       0.68      0.68      0.68      3676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_train,y_pred_bag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6165ecb",
   "metadata": {},
   "source": [
    "# BINGO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "80295c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DTC Bag Model - Teste 3 *** BINGO 1\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_bag})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//dtc_bag_3.csv\",index=False)\n",
    "\n",
    "# Nota: 0.954\n",
    "# DTC Bag w/ MICE Nan Values Max_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "fb97a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_model = BaggingClassifier(\n",
    "    base_estimator = RandomForestClassifier(),\n",
    "    n_estimators = 1000,\n",
    "    max_samples=0.9,\n",
    "    oob_score=True,\n",
    ")\n",
    "\n",
    "bag_model.fit(X_train, y_train)\n",
    "y_pred_bag_rf = bag_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b2b228b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      2920\n",
      "           1       0.21      0.18      0.19       756\n",
      "\n",
      "    accuracy                           0.69      3676\n",
      "   macro avg       0.50      0.50      0.50      3676\n",
      "weighted avg       0.68      0.69      0.68      3676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_train,y_pred_bag_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "15f0c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RF Bag Model - Teste 4\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_bag_rf})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//rf_bag_1.csv\",index=False)\n",
    "\n",
    "# Nota: 0.\n",
    "# RF Bag Scaled w/ MICE Nan Values Max_iter = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ce1f5",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295abd91",
   "metadata": {},
   "source": [
    "### 2.2. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "761c9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "036ee0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "58daa720",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest Hyperparameters - Teste 3\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_hrf})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//hrf_1.csv\",index=False)\n",
    "\n",
    "# Nota: 0.\n",
    "# Hyper Random Forest w/ MICE Nan Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1dc83984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations = 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [130, 160, 190],\n",
       " 'criterion': ['gini'],\n",
       " 'max_depth': [35, 55],\n",
       " 'min_samples_split': [0.001, 0.005],\n",
       " 'min_samples_leaf': [0.001, 0.005],\n",
       " 'max_features': ['log2']}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "n_estimators_list = [130,160,190]\n",
    "criterion_list = ['gini']\n",
    "max_depth_list = [20,55]\n",
    "min_samples_split_list = [0.001,0.005]\n",
    "min_samples_leaf_list = [0.001,0.005]\n",
    "max_features_list = ['log2']\n",
    "\n",
    "params_grid = {\n",
    "    'n_estimators':n_estimators_list,\n",
    "    'criterion':criterion_list,\n",
    "    'max_depth':max_depth_list,\n",
    "    'min_samples_split':min_samples_split_list,\n",
    "    'min_samples_leaf':min_samples_leaf_list,\n",
    "    'max_features':max_features_list\n",
    "}\n",
    "\n",
    "num_combinations = 1\n",
    "for k in params_grid.keys(): num_combinations *= len(params_grid[k])\n",
    "    \n",
    "print('Number of combinations =', num_combinations)\n",
    "params_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af45a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_roc_auc_score(model, X, y): return metrics.roc_auc_score(y_train, model.predict(X_train))\n",
    "\n",
    "model_rf = GridSearchCV(estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "                              param_grid=params_grid,\n",
    "                              cv=2,\n",
    "                              scoring=my_roc_auc_score,\n",
    "                              return_train_score=True,\n",
    "                              verbose=4)\n",
    "\n",
    "model_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8e941d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 35,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 0.001,\n",
       " 'min_samples_split': 0.001,\n",
       " 'n_estimators': 190}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "162c0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators = 130,\n",
    " min_samples_split = 0.0001,\n",
    " min_samples_leaf = 0.0001,\n",
    " max_features = 'sqrt',\n",
    " max_depth = 40,\n",
    " criterion = 'gini')\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred_hrf = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "85e8d36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      2920\n",
      "           1       0.21      0.20      0.20       756\n",
      "\n",
      "    accuracy                           0.68      3676\n",
      "   macro avg       0.50      0.50      0.50      3676\n",
      "weighted avg       0.68      0.68      0.68      3676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_train,y_pred_hrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "744eed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest Hyperparameters - Teste 4\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_hrf})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//hrf_3.csv\",index=False)\n",
    "\n",
    "# Nota: 0.90\n",
    "# Hyper Random Forest Scaled w/ MICE Nan Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "fa771cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest Hyperparameters - Teste 10\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_hrf})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//hrf_10.csv\",index=False)\n",
    "\n",
    "# Nota: 0.\n",
    "# Hyper Random Forest w/ MICE Nan Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "657b3548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:04:55] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:576: \n",
      "Parameters: { \"objectiver\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:55] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(objectiver='binary:logistic', n_estimators=50, scale_pos_weight=10)\n",
    "xgb_cl.fit(X_train, y_train, verbose=True)\n",
    "y_pred_xgb = xgb_cl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "75cac5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      2920\n",
      "           1       0.21      0.27      0.23       756\n",
      "\n",
      "    accuracy                           0.63      3676\n",
      "   macro avg       0.50      0.50      0.50      3676\n",
      "weighted avg       0.67      0.63      0.65      3676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_train,y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d5f12d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enzoaaragao/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:04:59] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:576: \n",
      "Parameters: { \"objectiver\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:59] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "### XGBoost - Teste 1\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(objectiver='binary:logistic', n_estimators=50, scale_pos_weight=10)\n",
    "xgb_cl.fit(X_train, y_train, verbose=True)\n",
    "y_pred_xgb = xgb_cl.predict(X_test)\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_xgb})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//xgb_2.csv\",index=False)\n",
    "\n",
    "# Nota: 0.914\n",
    "# XGBoost w/ MICE Nan Values T1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2886f636",
   "metadata": {},
   "source": [
    "# BINGO 2 - XGBOOST HYPERPARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c012eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridsearchCV\n",
    "\n",
    "#gbc = GradientBoostingClassifier()\n",
    "\n",
    "params = {'learning_rate':[0.001, 0.01, 0.1, 0.25, 0.5, 0.4],\n",
    "         'max_depth': [1,2,3,4,5,6,7,8,9,10],\n",
    "         'max_features':[1,2,3,4,5,6,7,8,9,10],\n",
    "         'n_estimators':[20,40,50,70,100]\n",
    "}\n",
    "\n",
    "model_xgb = GridSearchCV(XGBClassifier(),\n",
    "                          param_grid=params,\n",
    "                          cv=4,\n",
    "                          n_jobs=1,\n",
    "                         verbose=0)\n",
    "\n",
    "model_xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "fce4f288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.25,\n",
       " 'max_depth': 10,\n",
       " 'max_features': 1,\n",
       " 'n_estimators': 130}"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "926e4db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enzoaaragao/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:14:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:576: \n",
      "Parameters: { \"objectiver\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:14:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_cl = xgb.XGBClassifier(n_estimators=100, learning_rate=0.25, max_depth=8, scale_pos_weight=10, objectiver='binary:logistic')\n",
    "xgb_cl.fit(X_train, y_train, verbose=True)\n",
    "y_pred_xgb = xgb_cl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "baeae788",
   "metadata": {},
   "outputs": [],
   "source": [
    "### XGBoost - Teste 3\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(n_estimators=100, learning_rate=0.25, max_depth=8)\n",
    "xgb_cl.fit(X_train, y_train, verbose=True)\n",
    "y_pred_xgb = xgb_cl.predict(X_test)\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_xgb})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//xgb_h_3.csv\",index=False)\n",
    "\n",
    "# Nota: 0.\n",
    "# Hyper XGBoost w/ MICE Nan Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "91ed7a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:15:19] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "### XGBoost - Teste 5\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(n_estimators=100, learning_rate=0.25, max_depth=8)\n",
    "xgb_cl.fit(X_train, y_train, verbose=True)\n",
    "y_pred_xgb = xgb_cl.predict(X_test)\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_xgb})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//xgb_h_5.csv\",index=False)\n",
    "\n",
    "# Nota: 0.\n",
    "# Hyper XGBoost w/ MICE Nan Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "e0faa1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### XGBoost - Teste 4\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_xgb})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//xgb_h_4.csv\",index=False)\n",
    "\n",
    "# Nota: 0.\n",
    "# Hyper XGBoost w/ MICE Nan Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "c97d483f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:34:23] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:576: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:34:23] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "### XGBoost - Teste 6\n",
    "\n",
    "#learning_rate': 0.25,\n",
    "# 'max_depth': 10,\n",
    "# 'max_features': 1,\n",
    "# 'n_estimators': 130\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(n_estimators=130, learning_rate=0.25, max_depth = 10, max_features = 1)\n",
    "xgb_cl.fit(X_train, y_train, verbose=True)\n",
    "y_pred_xgb = xgb_cl.predict(X_test)\n",
    "\n",
    "#Generate CSV file for Submission\n",
    "res = pd.DataFrame(data={'i':test.iloc[:,0], 'y': y_pred_xgb})\n",
    "res.to_csv(\"//Users//enzoaaragao//Downloads//on-sale-ecd1//xgb_h_6.csv\",index=False)\n",
    "\n",
    "# Nota: 0.\n",
    "# Hyper XGBoost w/ MICE Nan Values & Standard - Teste 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb84029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
